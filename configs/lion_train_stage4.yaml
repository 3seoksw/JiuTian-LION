model:
  # Required model paths
  bert_model: "/path/to/bert-base-uncased/"
  vit_model: "/path/to/eva_vit_g.pth"
  llm_model: "/path/to/flan-t5-xl/"
  ram_model: "/path/to/ram_swin_large_14m.pth"

  # Model behavior
  visual_input: "ALL"
  enable_semantic_tags: True

  # Load a pretrained checkpoint
  load_pretrained: True
  pretrained: /path/to/XL_stage3.pth
  # stage3 checkpoint can be download at https://huggingface.co/daybreaksly/LION-FlanT5-XL-stage3

run:
  init_lr: 1e-5
  min_lr: 0
  weight_decay: 0.05
  max_epoch: 10
  num_workers: 8
  warmup_steps: 1000
  iters_per_epoch: 6000
  batch_size_train: 16
  mixed_precision: bf16
  output_dir: outputs/lion_stage4
  print_freq: 100

train_datasets:
  - ann_path: "/path/to/image_level_data.json"
    vis_root: "/path/to/image_folder"
    is_train: true
    sample_ratio: 1
  - ann_path: "/path/to/region_level_data.json"
    vis_root: "/path/to/image_folder"
    is_train: true
    sample_ratio: 1
